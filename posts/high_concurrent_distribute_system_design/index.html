<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>High_concurrent_distribute_system_design | slowpeace2020-blog</title>
<meta name=keywords content><meta name=description content="author: [&ldquo;Slowpeace&rdquo;] title: &ldquo;High_concurrent_distribute_system_design&rdquo; date: &ldquo;2024-05-17T09:46:58-04:00&rdquo; description: &ldquo;High_concurrent_distribute_system_design introduction&rdquo; tags: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;, &ldquo;concurrent&rdquo;] categories: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;] series: [&ldquo;Project&rdquo;] ShowToc: true TocOpen: true 案例1 如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；
案例2 另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。
基础篇 Scale-up vs Scale-out Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力 Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。 一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？ 拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。
使用缓存提升性能 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。 可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。
异步处理 什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。
异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。
系统演进方向 一般系统的演进过程应该遵循下面的思路："><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/high_concurrent_distribute_system_design/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5ff2630c4d1b3e25bc21f0ecd96681dbcf58219e741fa627857820b5485cb770.css integrity="sha256-X/JjDE0bPiW8IfDs2WaB289YIZ50H6YnhXggtUhct3A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/high_concurrent_distribute_system_design/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="High_concurrent_distribute_system_design"><meta property="og:description" content="author: [&ldquo;Slowpeace&rdquo;] title: &ldquo;High_concurrent_distribute_system_design&rdquo; date: &ldquo;2024-05-17T09:46:58-04:00&rdquo; description: &ldquo;High_concurrent_distribute_system_design introduction&rdquo; tags: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;, &ldquo;concurrent&rdquo;] categories: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;] series: [&ldquo;Project&rdquo;] ShowToc: true TocOpen: true 案例1 如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；
案例2 另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。
基础篇 Scale-up vs Scale-out Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力 Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。 一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？ 拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。
使用缓存提升性能 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。 可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。
异步处理 什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。
异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。
系统演进方向 一般系统的演进过程应该遵循下面的思路："><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/high_concurrent_distribute_system_design/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-17T09:46:58-04:00"><meta property="article:modified_time" content="2024-05-17T09:46:58-04:00"><meta property="og:site_name" content="slowpeace2020-blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="High_concurrent_distribute_system_design"><meta name=twitter:description content="author: [&ldquo;Slowpeace&rdquo;] title: &ldquo;High_concurrent_distribute_system_design&rdquo; date: &ldquo;2024-05-17T09:46:58-04:00&rdquo; description: &ldquo;High_concurrent_distribute_system_design introduction&rdquo; tags: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;, &ldquo;concurrent&rdquo;] categories: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;] series: [&ldquo;Project&rdquo;] ShowToc: true TocOpen: true 案例1 如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；
案例2 另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。
基础篇 Scale-up vs Scale-out Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力 Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。 一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？ 拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。
使用缓存提升性能 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。 可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。
异步处理 什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。
异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。
系统演进方向 一般系统的演进过程应该遵循下面的思路："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"High_concurrent_distribute_system_design","item":"http://localhost:1313/posts/high_concurrent_distribute_system_design/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"High_concurrent_distribute_system_design","name":"High_concurrent_distribute_system_design","description":"author: [\u0026ldquo;Slowpeace\u0026rdquo;] title: \u0026ldquo;High_concurrent_distribute_system_design\u0026rdquo; date: \u0026ldquo;2024-05-17T09:46:58-04:00\u0026rdquo; description: \u0026ldquo;High_concurrent_distribute_system_design introduction\u0026rdquo; tags: [\u0026ldquo;system design\u0026rdquo;, \u0026ldquo;distribute\u0026rdquo;, \u0026ldquo;concurrent\u0026rdquo;] categories: [\u0026ldquo;system design\u0026rdquo;, \u0026ldquo;distribute\u0026rdquo;] series: [\u0026ldquo;Project\u0026rdquo;] ShowToc: true TocOpen: true 案例1 如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；\n案例2 另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。\n基础篇 Scale-up vs Scale-out Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力 Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。 一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？ 拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。\n使用缓存提升性能 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。 可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。\n异步处理 什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。\n异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。\n系统演进方向 一般系统的演进过程应该遵循下面的思路：","keywords":[],"articleBody":" author: [“Slowpeace”] title: “High_concurrent_distribute_system_design” date: “2024-05-17T09:46:58-04:00” description: “High_concurrent_distribute_system_design introduction” tags: [“system design”, “distribute”, “concurrent”] categories: [“system design”, “distribute”] series: [“Project”] ShowToc: true TocOpen: true 案例1 如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；\n案例2 另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。\n基础篇 Scale-up vs Scale-out Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力 Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。 一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？ 拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。\n使用缓存提升性能 普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。 可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。\n异步处理 什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。\n异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。\n系统演进方向 一般系统的演进过程应该遵循下面的思路：\n最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。 随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。 当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题\n架构分层 分层的好处：专注设计应用层的程序，模块复用，减少研发周期，提升研发的效率，更容易做横向扩展scale-out 缺点：最主要的一个缺陷就是增加了代码的复杂度，多层的架构在性能上会有损耗（多一跳问题），\n怎么做分层 每个层次的边界是什么？ 终端显示层：前端的各种渲染，页面展示 开放接口层：对外的API接口，也负责网关、流量控制 Web层：对访问控制进行转发，参数校验，不复用的简单业务处理 业务逻辑层：Service层 Manager层：通用业务处理，将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互的策略，中间件的接入； 封装对第三方接口的调用，比如支付、审核服务 DAO层：数据访问层，和各种数据库比如MySQL，Oracle, HBase等交互 外部接口或者第三方平台：其他部门的RPC接口，基础平台，其他公司的HTTP接口\n层次划分原则：层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转 单一职责原则single responsibility principle 迪米特法则Law of Demeter 开闭原则open-close principle\n系统设计目标：高性能 高并发：毫秒级响应时间，99.999%的可用性\n性能优化原则 有问题再优化，不要提前复杂化 八二原则，优化主要的性能瓶颈 数据支撑，你的优化让响应时间减少了多少，提升了多少吞吐量\n性能的衡量指标 系统响应时间：平均值、最大值、分位值（越大，对于慢请求的影响越敏感，适合时间段内统计） 吞吐量和同时在线用户数：衡量并发和流量 健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。\n性能优化 假设执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次，如何来优化性能从而提高系统的并发能力呢？\n提高系统的处理核心数 吞吐量 = 并发进程数 / 响应时间 随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的 拐点模型。\n我们在评估系统性能时通常需要做压力测试，目的就是找到系统的「拐点」，从而知道系统的承载能力，也便于找到系统的瓶颈，持续优化系统性能。\n减少单次任务的响应时间 想要减少任务的响应时间，首先要看你的系统是 CPU 密集型 还是 IO 密集型 的，因为不同类型的系统性能优化方式不尽相同。\nCPU 密集型系统 CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。 现这类问题的主要方式，是通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块，比如 Linux 的 perf、eBPF 等。\nIO 密集型系统 IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。 一种是采用工具，Linux 的工具集很丰富，完全可以满足你的优化需要，比如网络协议栈、网卡、磁盘、文件系统、内存，等等。这些工具的用法很多，你可以在排查问题的过程中逐渐积累。\n另外一类手段就是可以通过 监控 来发现性能问题。在监控中我们可以对任务的每一个步骤做分时的统计，从而找到任务的哪一步消耗了更多的时间\n那么找到了系统的瓶颈点，我们要如何优化呢？优化方案会随着问题的不同而不同。比方说，如果是数据库访问慢，那么就要看是不是有锁表的情况、是不是有全表扫描、索引加得是否合适、是否有 JOIN 操作、需不需要加缓存，等等；如果是网络的问题，就要看网络的参数是否有优化的空间，抓包来看是否有大量的超时重传，网卡是否有大量丢包等。\n系统设计目标：高可用High Availability，HA 系统具备较高的无故障运行的能力。 MTBF（Mean Time Between Failure） 平均故障间隔 MTTR（Mean Time To Repair） 故障的平均恢复时间\n可用性度量 可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：\nAvailability = MTBF / (MTBF + MTTR)\n一般来说，我们的核心业务系统的可用性，需要达到四个九，非核心系统的可用性最多容忍到三个九。\n系统设计 开发实现阶段，注重的是如何处理故障，关键词是 冗余和取舍\nfailover（故障转移） 完全对等 的节点之间做 failover：无状态，stateless,如果访问某一个节点失败，那么简单地随机访问另一个节点就好了 不对等 的节点之间，即系统中存在主节点也存在备节点: stateful, 这些备用节点可以是热备（同样在线提供服务的备用节点），也可以是冷备（只作为备份使用），那么我们就需要在代码中控制如何检测主备机器是否故障，以及如何做主备切换。\n使用最广泛的故障检测机制是「心跳」。你可以在客户端上定期地向主节点发送心跳包，也可以从备份节点上定期发送心跳包。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。\n选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比方说 Paxos，Raft。\n调用超时控制 超时引发的问题：因为失败通常是瞬时的，可以通过重试的方式解决。而一旦调用某一个模块或者服务发生比较大的延迟，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。 可以通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间。\n超时控制实际上就是不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用。这对于用户来说是有损的，但是却是必要的，因为它牺牲了少量的请求却保证了整体系统的可用性。而我们还有另外两种有损的方案能保证系统的高可用，它们就是降级和限流。\n降级 降级是为了保证核心服务的稳定而牺牲非核心服务的做法。关闭非核心服务。\n限流 对并发的请求进行限速来保护系统。它是在极端并发下的无奈之举，是短暂的行为，因此是可以接受的。\n系统运维 从 运维角度 来看则更偏保守，注重的是如何避免故障的发生。\n灰度发布 90% 的故障是发生在上线变更阶段，重视变更管理尤为重要。而除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外， 另一个主要的手段就是灰度发布。 灰度发布是以机器维度进行的。比方说，我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。\n故障演练 故障演练和时下比较流行的“混沌工程”的思路如出一辙， 作为混沌工程的鼻祖，Netfix 在 2010 年推出的 Chaos Monkey 工具就是故障演练绝佳的工具。它通过在线上系统上随机地关闭线上节点来模拟故障，让工程师可以了解，在出现此类故障时会有什么样的影响。\n针对于操作系统，网络或磁盘这种应该怎么故障注入，故障模拟应该怎么模拟呢？ 一般使用 tc 来模拟网络慢的情况，磁盘故障可以使用 fiu-ctrl\n系统设计目标：易扩展 高可扩展性是一个设计的指标，它表示可以通过增加机器的方式来线性提高系统的处理能力，从而承担更高的流量和并发 。 一般来说，基于成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高。\n数据库、缓存、依赖的第三方、负载均衡、交换机带宽等等 都是系统扩展时需要考虑的因素。我们要知道系统并发到了某一个量级之后，哪一个因素会成为我们的瓶颈点，从而针对性地进行扩展。\n拆分 把庞杂的系统拆分成独立的，有单一职责的模块。将复杂的问题简单化，这就是我们的思路。\n存储层的扩展性 存储拆分首先考虑的维度是业务维度。\n按照业务拆分，在一定程度上提升了系统的扩展性，但系统运行时间长了之后，单一的业务数据库在容量和并发请求量上仍然会超过单机的限制。 这时，我们就需要针对数据库做第二次拆分。这次拆分是按照数据特征做水平的拆分 ，比如说我们可以给用户库增加两个节点，然后按照某些算法将用户的数据拆分到这三个库里面。\n基于长远考虑，我们最好一次性增加足够的节点以避免频繁地扩容。 当数据库按照业务和数据维度拆分之后，我们 尽量不要使用事务。因为当一个事务中同时更新不同的数据库时，需要使用二阶段提交，来协调所有数据库要么全部更新成功，要么全部更新失败。这个协调的成本会随着资源的扩展不断升高，最终达到无法承受的程度。\n业务层的扩展性 我们一般会从三个维度考虑业务层的拆分方案，它们分别是：业务维度 ，重要性维度 和 请求来源维度。\n我们需要把相同业务的服务拆分成单独的业务池，每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源。这样当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方就可以了，这样就大大减少了扩容的复杂度。\n我们还可以根据业务接口的重要程度，把业务分为核心池和非核心池 （池子就是一组机器组成的集群） 。优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。\n还可以根据接入客户端类型的不同做业务池的拆分。比如说，服务于客户端接口的业务可以定义为外网池，服务于小程序或者 HTML5 页面的业务可以定义为 H5 池，服务于内部其它部门的业务可以定义为内网池，等等。\n","wordCount":"283","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-05-17T09:46:58-04:00","dateModified":"2024-05-17T09:46:58-04:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/high_concurrent_distribute_system_design/"},"publisher":{"@type":"Organization","name":"slowpeace2020-blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="slowpeace2020-blog (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>slowpeace2020-blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=https://slowpeace2020.github.io/ title=slowpeace2020><span>slowpeace2020</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">High_concurrent_distribute_system_design
<span class=entry-hint title=Draft><svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2024-05-17 09:46:58 -0400 -0400'>May 17, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;283 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/high_concurrent_distribute_system_design.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><hr><h2 id=tocopen-true>author: [&ldquo;Slowpeace&rdquo;]
title: &ldquo;High_concurrent_distribute_system_design&rdquo;
date: &ldquo;2024-05-17T09:46:58-04:00&rdquo;
description: &ldquo;High_concurrent_distribute_system_design introduction&rdquo;
tags: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;, &ldquo;concurrent&rdquo;]
categories: [&ldquo;system design&rdquo;, &ldquo;distribute&rdquo;]
series: [&ldquo;Project&rdquo;]
ShowToc: true
TocOpen: true</h2><h2 id=案例1>案例1<a hidden class=anchor aria-hidden=true href=#案例1>#</a></h2><blockquote><p>如何设计承担每秒几十万次用户未读数请求的系统。 之所以选择它，是因为在大部分的系统中未读数都会是请求量最大、并发最高的服务，在微博时 QPS 会达到每秒 50 万次。同时，未读数系统的业务逻辑比较简单，在你了解设计方案的时候也不需要预先对业务逻辑有深入了解；</p></blockquote><h2 id=案例2>案例2<a hidden class=anchor aria-hidden=true href=#案例2>#</a></h2><blockquote><p>另一个例子是信息流系统的设计，它是社区社交产品中的核心系统，业务逻辑复杂且请求量大，方案中几乎涉及高并发系统设计的全部内容。</p></blockquote><h2 id=基础篇>基础篇<a hidden class=anchor aria-hidden=true href=#基础篇>#</a></h2><h3 id=scale-up-vs-scale-out>Scale-up vs Scale-out<a hidden class=anchor aria-hidden=true href=#scale-up-vs-scale-out>#</a></h3><p>Scale-up: 通过购买性能更好的硬件来提升系统的并发处理能力
Scale-out: 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。
一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？
拿 Scale-out 来说，数据库一主多从、分库分表、存储分片都是它的实际应用方案。</p><h3 id=使用缓存提升性能>使用缓存提升性能<a hidden class=anchor aria-hidden=true href=#使用缓存提升性能>#</a></h3><p>普通磁盘的寻道时间是 10ms 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 ns（纳秒）级别，从千兆网卡上读取数据的时间是在 μs（微秒）级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。
可以将任何降低响应时间的中间存储都称为缓存。缓存的思想遍布很多设计领域，比如在操作系统中 CPU 有多级缓存，文件有 Page Cache 缓存。</p><h3 id=异步处理>异步处理<a hidden class=anchor aria-hidden=true href=#异步处理>#</a></h3><p>什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。</p><p>异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。</p><h3 id=系统演进方向>系统演进方向<a hidden class=anchor aria-hidden=true href=#系统演进方向>#</a></h3><p>一般系统的演进过程应该遵循下面的思路：</p><p>最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。
随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。
当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题</p><h2 id=架构分层>架构分层<a hidden class=anchor aria-hidden=true href=#架构分层>#</a></h2><p>分层的好处：专注设计应用层的程序，模块复用，减少研发周期，提升研发的效率，更容易做横向扩展scale-out
缺点：最主要的一个缺陷就是增加了代码的复杂度，多层的架构在性能上会有损耗（多一跳问题），</p><h3 id=怎么做分层>怎么做分层<a hidden class=anchor aria-hidden=true href=#怎么做分层>#</a></h3><p>每个层次的边界是什么？
<img loading=lazy src=../../assets/images/layer.png alt=分层参考></p><p>终端显示层：前端的各种渲染，页面展示
开放接口层：对外的API接口，也负责网关、流量控制
Web层：对访问控制进行转发，参数校验，不复用的简单业务处理
业务逻辑层：Service层
Manager层：通用业务处理，将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互的策略，中间件的接入；
封装对第三方接口的调用，比如支付、审核服务
DAO层：数据访问层，和各种数据库比如MySQL，Oracle, HBase等交互
外部接口或者第三方平台：其他部门的RPC接口，基础平台，其他公司的HTTP接口</p><p>层次划分原则：层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转
单一职责原则single responsibility principle
迪米特法则Law of Demeter
开闭原则open-close principle</p><h2 id=系统设计目标高性能>系统设计目标：高性能<a hidden class=anchor aria-hidden=true href=#系统设计目标高性能>#</a></h2><p>高并发：毫秒级响应时间，99.999%的可用性</p><h3 id=性能优化原则>性能优化原则<a hidden class=anchor aria-hidden=true href=#性能优化原则>#</a></h3><p>有问题再优化，不要提前复杂化
八二原则，优化主要的性能瓶颈
数据支撑，你的优化让响应时间减少了多少，提升了多少吞吐量</p><h3 id=性能的衡量指标>性能的衡量指标<a hidden class=anchor aria-hidden=true href=#性能的衡量指标>#</a></h3><p>系统响应时间：平均值、最大值、分位值（越大，对于慢请求的影响越敏感，适合时间段内统计）
吞吐量和同时在线用户数：衡量并发和流量
健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。</p><h3 id=性能优化>性能优化<a hidden class=anchor aria-hidden=true href=#性能优化>#</a></h3><p>假设执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次，如何来优化性能从而提高系统的并发能力呢？</p><h4 id=提高系统的处理核心数>提高系统的处理核心数<a hidden class=anchor aria-hidden=true href=#提高系统的处理核心数>#</a></h4><p>吞吐量 = 并发进程数 / 响应时间
随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的 拐点模型。</p><p>我们在评估系统性能时通常需要做压力测试，目的就是找到系统的「拐点」，从而知道系统的承载能力，也便于找到系统的瓶颈，持续优化系统性能。</p><h4 id=减少单次任务的响应时间>减少单次任务的响应时间<a hidden class=anchor aria-hidden=true href=#减少单次任务的响应时间>#</a></h4><p>想要减少任务的响应时间，首先要看你的系统是 CPU 密集型 还是 IO 密集型 的，因为不同类型的系统性能优化方式不尽相同。</p><h5 id=cpu-密集型系统>CPU 密集型系统<a hidden class=anchor aria-hidden=true href=#cpu-密集型系统>#</a></h5><p>CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。
现这类问题的主要方式，是通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块，比如 Linux 的 perf、eBPF 等。</p><h5 id=io-密集型系统>IO 密集型系统<a hidden class=anchor aria-hidden=true href=#io-密集型系统>#</a></h5><p>IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。
一种是采用工具，Linux 的工具集很丰富，完全可以满足你的优化需要，比如网络协议栈、网卡、磁盘、文件系统、内存，等等。这些工具的用法很多，你可以在排查问题的过程中逐渐积累。<br>另外一类手段就是可以通过 监控 来发现性能问题。在监控中我们可以对任务的每一个步骤做分时的统计，从而找到任务的哪一步消耗了更多的时间</p><p>那么找到了系统的瓶颈点，我们要如何优化呢？优化方案会随着问题的不同而不同。比方说，如果是数据库访问慢，那么就要看是不是有锁表的情况、是不是有全表扫描、索引加得是否合适、是否有 JOIN 操作、需不需要加缓存，等等；如果是网络的问题，就要看网络的参数是否有优化的空间，抓包来看是否有大量的超时重传，网卡是否有大量丢包等。</p><h2 id=系统设计目标高可用high-availabilityha>系统设计目标：高可用High Availability，HA<a hidden class=anchor aria-hidden=true href=#系统设计目标高可用high-availabilityha>#</a></h2><p>系统具备较高的无故障运行的能力。
<strong>MTBF（Mean Time Between Failure）</strong> 平均故障间隔
<strong>MTTR（Mean Time To Repair）</strong> 故障的平均恢复时间</p><h3 id=可用性度量>可用性度量<a hidden class=anchor aria-hidden=true href=#可用性度量>#</a></h3><p>可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：</p><p>Availability = MTBF / (MTBF + MTTR)</p><p><img loading=lazy src=../../assets/images/failure_time.png alt=故障时间>
一般来说，我们的核心业务系统的可用性，需要达到四个九，非核心系统的可用性最多容忍到三个九。</p><h3 id=系统设计>系统设计<a hidden class=anchor aria-hidden=true href=#系统设计>#</a></h3><p>开发实现阶段，注重的是如何处理故障，关键词是 冗余和取舍</p><h4 id=failover故障转移>failover（故障转移）<a hidden class=anchor aria-hidden=true href=#failover故障转移>#</a></h4><p>完全对等 的节点之间做 failover：无状态，stateless,如果访问某一个节点失败，那么简单地随机访问另一个节点就好了
不对等 的节点之间，即系统中存在主节点也存在备节点: stateful, 这些备用节点可以是热备（同样在线提供服务的备用节点），也可以是冷备（只作为备份使用），那么我们就需要在代码中控制如何检测主备机器是否故障，以及如何做主备切换。</p><p>使用最广泛的故障检测机制是「心跳」。你可以在客户端上定期地向主节点发送心跳包，也可以从备份节点上定期发送心跳包。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。</p><p>选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比方说 Paxos，Raft。</p><h4 id=调用超时控制>调用超时控制<a hidden class=anchor aria-hidden=true href=#调用超时控制>#</a></h4><p>超时引发的问题：因为失败通常是瞬时的，可以通过重试的方式解决。而一旦调用某一个模块或者服务发生比较大的延迟，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。
可以通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间。</p><p>超时控制实际上就是不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用。这对于用户来说是有损的，但是却是必要的，因为它牺牲了少量的请求却保证了整体系统的可用性。而我们还有另外两种有损的方案能保证系统的高可用，它们就是降级和限流。</p><h4 id=降级>降级<a hidden class=anchor aria-hidden=true href=#降级>#</a></h4><p>降级是为了保证核心服务的稳定而牺牲非核心服务的做法。关闭非核心服务。</p><h4 id=限流>限流<a hidden class=anchor aria-hidden=true href=#限流>#</a></h4><p>对并发的请求进行限速来保护系统。它是在极端并发下的无奈之举，是短暂的行为，因此是可以接受的。</p><h3 id=系统运维>系统运维<a hidden class=anchor aria-hidden=true href=#系统运维>#</a></h3><p>从 运维角度 来看则更偏保守，注重的是如何避免故障的发生。</p><h4 id=灰度发布>灰度发布<a hidden class=anchor aria-hidden=true href=#灰度发布>#</a></h4><p>90% 的故障是发生在上线变更阶段，重视变更管理尤为重要。而除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外， 另一个主要的手段就是灰度发布。
灰度发布是以机器维度进行的。比方说，我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。</p><h4 id=故障演练>故障演练<a hidden class=anchor aria-hidden=true href=#故障演练>#</a></h4><p>故障演练和时下比较流行的“混沌工程”的思路如出一辙， 作为混沌工程的鼻祖，Netfix 在 2010 年推出的 Chaos Monkey 工具就是故障演练绝佳的工具。它通过在线上系统上随机地关闭线上节点来模拟故障，让工程师可以了解，在出现此类故障时会有什么样的影响。</p><p>针对于操作系统，网络或磁盘这种应该怎么故障注入，故障模拟应该怎么模拟呢？
一般使用 tc 来模拟网络慢的情况，磁盘故障可以使用 fiu-ctrl</p><h2 id=系统设计目标易扩展>系统设计目标：易扩展<a hidden class=anchor aria-hidden=true href=#系统设计目标易扩展>#</a></h2><p>高可扩展性是一个设计的指标，它表示可以通过增加机器的方式来线性提高系统的处理能力，从而承担更高的流量和并发 。
一般来说，基于成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高。</p><p>数据库、缓存、依赖的第三方、负载均衡、交换机带宽等等 都是系统扩展时需要考虑的因素。我们要知道系统并发到了某一个量级之后，哪一个因素会成为我们的瓶颈点，从而针对性地进行扩展。</p><h3 id=拆分>拆分<a hidden class=anchor aria-hidden=true href=#拆分>#</a></h3><p>把庞杂的系统拆分成独立的，有单一职责的模块。将复杂的问题简单化，这就是我们的思路。</p><h4 id=存储层的扩展性>存储层的扩展性<a hidden class=anchor aria-hidden=true href=#存储层的扩展性>#</a></h4><p>存储拆分首先考虑的维度是业务维度。<br>按照业务拆分，在一定程度上提升了系统的扩展性，但系统运行时间长了之后，单一的业务数据库在容量和并发请求量上仍然会超过单机的限制。 这时，我们就需要针对数据库做第二次拆分。这次拆分是按照数据特征做水平的拆分 ，比如说我们可以给用户库增加两个节点，然后按照某些算法将用户的数据拆分到这三个库里面。<br>基于长远考虑，我们最好一次性增加足够的节点以避免频繁地扩容。
当数据库按照业务和数据维度拆分之后，我们 尽量不要使用事务。因为当一个事务中同时更新不同的数据库时，需要使用二阶段提交，来协调所有数据库要么全部更新成功，要么全部更新失败。这个协调的成本会随着资源的扩展不断升高，最终达到无法承受的程度。</p><h4 id=业务层的扩展性>业务层的扩展性<a hidden class=anchor aria-hidden=true href=#业务层的扩展性>#</a></h4><p>我们一般会从三个维度考虑业务层的拆分方案，它们分别是：业务维度 ，重要性维度 和 请求来源维度。</p><p>我们需要把相同业务的服务拆分成单独的业务池，每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源。这样当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方就可以了，这样就大大减少了扩容的复杂度。<br>我们还可以根据业务接口的重要程度，把业务分为核心池和非核心池 （池子就是一组机器组成的集群） 。优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。<br>还可以根据接入客户端类型的不同做业务池的拆分。比如说，服务于客户端接口的业务可以定义为外网池，服务于小程序或者 HTML5 页面的业务可以定义为 H5 池，服务于内部其它部门的业务可以定义为内网池，等等。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/interview_note/><span class=title>« Prev</span><br><span>High_concurrent_distribute_system_design</span>
</a><a class=next href=http://localhost:1313/posts/test/><span class=title>Next »</span><br><span>Test</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on x" href="https://x.com/intent/tweet/?text=High_concurrent_distribute_system_design&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f&amp;title=High_concurrent_distribute_system_design&amp;summary=High_concurrent_distribute_system_design&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f&title=High_concurrent_distribute_system_design"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on whatsapp" href="https://api.whatsapp.com/send?text=High_concurrent_distribute_system_design%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on telegram" href="https://telegram.me/share/url?text=High_concurrent_distribute_system_design&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on ycombinator" href="https://news.ycombinator.com/submitlink?t=High_concurrent_distribute_system_design&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fhigh_concurrent_distribute_system_design%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>slowpeace2020-blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>