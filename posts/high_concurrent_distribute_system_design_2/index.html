<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>High_concurrent_distribute_system_design | slowpeace2020-blog</title>
<meta name=keywords content="system design,distribute,concurrent"><meta name=description content="High_concurrent_distribute_system_design introduction"><meta name=author content="Slowpeace"><link rel=canonical href=https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_2/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5ff2630c4d1b3e25bc21f0ecd96681dbcf58219e741fa627857820b5485cb770.css integrity="sha256-X/JjDE0bPiW8IfDs2WaB289YIZ50H6YnhXggtUhct3A=" rel="preload stylesheet" as=style><link rel=icon href=https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="High_concurrent_distribute_system_design"><meta property="og:description" content="High_concurrent_distribute_system_design introduction"><meta property="og:type" content="article"><meta property="og:url" content="https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_2/"><meta property="og:image" content="https://slowpeace2020.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-23T09:41:46-04:00"><meta property="article:modified_time" content="2024-05-23T09:41:46-04:00"><meta property="og:site_name" content="slowpeace2020-blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://slowpeace2020.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="High_concurrent_distribute_system_design"><meta name=twitter:description content="High_concurrent_distribute_system_design introduction"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://slowpeace2020.github.io/posts/"},{"@type":"ListItem","position":2,"name":"High_concurrent_distribute_system_design","item":"https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"High_concurrent_distribute_system_design","name":"High_concurrent_distribute_system_design","description":"High_concurrent_distribute_system_design introduction","keywords":["system design","distribute","concurrent"],"articleBody":"演进篇之缓存 缓存定义 凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存 。缓存作为一种常见的 空间换时间的性能优化手段。\n我们熟知的 HTTP 协议也是有缓存机制的。**当我们第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个 Etag 的字段。浏览器会缓存图片信息以及这个字段的值。当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个 If-None-Match 的字段，并且把缓存的 Etag 的值写进去发给服务端。服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息。通过这种缓存协商的方式，可以减少网络传输的数据大小，从而提升页面展示的性能。\n缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。 缓冲区更像「消息队列篇」中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差 。\n静态缓存、分布式缓存和热点本地缓存 静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。\n对于动态的请求你可以选择分布式缓存\n什么时候要考虑热点本地缓存呢？\n答案是当我们遇到极端的热点数据查询的时候。 热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。 我们会在代码中使用一些本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。 由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。\n缓存的缺点 缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。 缓存会给整体系统带来复杂度，并且会有数据不一致的风险。 缓存通常使用内存作为存储介质，但是内存并不是无限的。 缓存会给运维也带来一定的成本。\n缓存可以有多层，静态缓存处在负载均衡层，分布式缓存处在应用层和数据库层之间，本地缓存处在应用层。我们需要将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差； 缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高。\n如何选择缓存策略 Cache Aside 变更数据库和变更缓存是两个独立的操作，而我们并没有对操作做任何的并发控制。那么当两个线程并发更新它们的时候，就会因为写入顺序的不同造成数据的不一致。\n那我们要如何解决这个问题呢？ 其实，我们可以在更新数据时不更新缓存，而是删除缓存中的数据，在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。\nCache Aside 策略（也叫旁路缓存策略），这个策略数据 以数据库中的数据为准，缓存中的数据是按需加载的 。它可以分为读策略和写策略，\n读策略的步骤是：\n从缓存中读取数据； 如果缓存命中，则直接返回数据； 如果缓存不命中，则从数据库中查询数据； 查询到数据后，将数据写入到缓存中，并且返回给用户。\n写策略的步骤是：\n更新数据库中的记录； 删除缓存记录。\n像 Cache Aside 策略这样先更新数据库，后删除缓存就没有问题了吗？ 其实在理论上还是有缺陷的。假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中，造成缓存和数据库数据不一致。\n不过这种问题出现的几率并不高，原因是缓存的写入通常远远快于数据库的写入 ，所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。\nCache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。 如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：\n一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响； 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。\nRead/Write Through（读穿 / 写穿）策略 这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。\nWrite Through 的策略是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做 Write Miss（写失效）。\n我们可以选择两种 Write Miss 方式：\nWrite Allocate（按写分配）\n做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；\nNo-write allocate（不按写分配）\n做法是不写入缓存中，而是直接更新到数据库中\n在 Write Through 策略中，我们一般选择 No-write allocate 方式，原因是无论采用哪种 Write Miss 方式，我们都需要同步将数据更新到数据库中，而 No-write allocate 方式相比 Write Allocate 还减少了一次缓存的写入，能够提升写入的性能。\nRead Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。\nRead Through/Write Through 策略的特点是 **由缓存节点而非用户来和数据库打交道 **，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。\n我们看到 Write Through 策略中写数据库是同步的 ，这对于性能来说会有比较大的影响，因为相比于写缓存，同步写数据库的延迟就要高很多了。那么我们可否异步地更新数据库？这就是我们接下来要提到的 Write Back 策略。\nWrite Back（写回）策略 在写入数据时只写入缓存，并且把缓存块标记为 「脏」 的。而脏块只有被再次使用时才会将其中的数据写入到后端存储中。\n在 Write Miss 的情况下，我们采用的是 Write Allocate 的方式，也就是在写入后端存储的同时要写入缓存，这样我们在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了\n其实这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑。\n也可以用在日志、统计等实时性不高的场景\n总结 Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。\nRead/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；\nWrite Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。\n怎么保证缓存的高可用 分布式缓存三大类\n客户端 客户端配置缓存节点 写入时将数据分散到多个节点，也就是数据分片 读则利用多组缓存做容错，提升缓存系统的可用性，\n怎么分片？ 取模，实现简单，但是增减节点比较麻烦\n一致性哈希，用虚拟节点解决热点数据分布不均匀的问题，可能会产生脏数据，设置过期时间 缺点是让缓存的使用变得复杂，在批量获取（MultiGET）时，单个节点的访问量并没有减少，而且节点太多会造成缓存访问的SLA(服务等级协议)得不到保证，因为它取决于最慢、最坏的节点，4-6个节点比较合适\nMemchached 主从机制 redis支持，但是memcached不支持，怎么在客户端实现呢？ 为每一组 Master 配置一组 Slave，更新数据时主从同步更新。读取时，优先从 Slave 中读数据，如果读取不到数据就穿透到 Master 读取，并且将数据回种到 Slave 中以保持 Slave 数据的热度。 主从机制最大的优点就是当某一个 Slave 宕机时，还会有 Master 作为兜底，不会有大量请求穿透到数据库的情况发生，提升了缓存系统的高可用性。\n多副本 主从模式解决绝大多数场景，极端流量场景下，一组slave不能承担所有流量，Slave的网卡带宽可能成为瓶颈，可以考虑在 Master/Slave 之前增加一层副本层 当客户端发起查询请求时，请求首先会先从多个副本组中选取一个副本组发起查询，如果查询失败，就继续查询 Master/Slave，并且将查询的结果回种到所有副本组中，避免副本组中脏数据的存在。\n基于成本的考虑，每一个副本组容量比 Master 和 Slave 要小，因此它只存储了更加热的数据。\n客户端方案可以解决大部分问题，但是只能在单一语言系统之间复用。中间代理层可以解决这个问题。\n中间代理层 将客户端方案中的高可用逻辑封装在代理层代码里面，这样用户在使用你的代理层的时候就不需要关心缓存的高可用是如何做的，只需要依赖你的代理层就好了。 业界的中间代理层方案，比如 Facebook 的 Mcrouter，Twitter 的 Twemproxy，豌豆荚的 Codis 所有缓存的 读写请求 都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用的逻辑，不同的开源中间代理层方案中使用的高可用策略各有不同。比如在 Twemproxy 中，Proxy 保证在某一个 Redis 节点挂掉之后会把它从集群中移除，后续的请求将由其他节点来完成；而 Codis 的实现略复杂，它提供了一个叫 Codis Ha 的工具来实现自动从节点提主节点，在 3.2 版本之后换做了 Redis Sentinel 方式，从而实现 Redis 节点的高可用。\n服务端 Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性。\n缓存穿透怎么办 我们解决缓存穿透问题的 核心目标在于减少对于数据库的并发请求。 核心缓存的命中率要保持在 99% 以上，非核心缓存的命中率也要尽量保证在 90%，如果低于这个标准，那么可能就需要优化缓存的使用方式了。\n回写空值 不存在的数据会反复查询数据库，或者由于bug，那就写一个空值在缓存中，设置较短的过期时间。要注意大量空值的情况，考虑缓存容量\n布隆过滤器 布隆过滤器是由一个二进制数组和一个 Hash 算法组成的 针对容量大的情况，用布隆过滤器映射所有数据，提前判断是否有值，没有就直接挡住，不必再查 读写时间复杂度都是O(1)\n缺点： 误判，有可能不在，但是判断存在集合中； 不支持删除元素；\n解决方案：\n使用多个hash函数计算出多个hash值，只有都为1，才代表存在； 数组中不再只有0和1，根据出现次数计数，删除时减一； 热点数据失效，导致缓存并发穿透，怎么解决？\n代码中启动后台线程，热点缓存失效之后将数据加载到缓存； memcached或者redis分布式锁，只有获取到锁的请求才能查询数据库； 静态资源加速 静态资源访问关键点：就近访问\n在业务服务器上层，增加特殊的缓存，来承担静态资源访问：CDN\nCDN系统 怎么把用户的请求映射到CDN节点？ 怎么根据用户的地理位置信息选择近的节点？\n静态资源url处理，将第三方厂商提供的 IP 隐藏起来，给到用户的最好是一个本公司域名的子域名。 通过DNS解决域名映射问题，域名解析两种方式：\nA记录，返回域名对应IP； CNAME域名，返回另外一个域名； 域名解析步骤？ 以 www.baidu.com 这个域名为例给你简单介绍一下域名解析的过程：\n一开始，域名解析请求先会检查本机的 hosts 文件，查看是否有 www.baidu.com 对应的 IP；\n如果没有的话，就请求 Local DNS 是否有域名解析结果的缓存，如果有就返回，标识是从非权威 DNS 返回的结果；\n如果没有，就开始 DNS 的迭代查询：\n先请求根 DNS，根 DNS 返回顶级 DNS（.com）的地址； 再请求 .com 顶级 DNS，得到 baidu.com 的域名服务器地址； 再从 baidu.com 的域名服务器中查询到 www.baidu.com 对应的 IP 地址，返回这个 IP 地址的同时，标记这个结果是来自于权威 DNS 的结果，同时写入 Local DNS 的解析结果缓存，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。 经过了向多个 DNS 服务器做查询之后，整个 DNS 的解析的时间有可能会到秒级别。\n那么我们如何来解决这个解析性能问题呢？ 在APP启动时，对要解析的域名预先解析，将解析结果缓存到本地LRU缓存，用定时器定期更新缓存\nGlobal Server Load Balance，全局负载均衡 作用：\n负载均衡； 保证流量流经的服务器离流量源头近； 找到离用户最近的CDN节点 是否能够从 CDN 节点上获取到资源还取决于 CDN 的同步延时。 一般，我们会通过 CDN 厂商的接口将静态的资源写入到某一个 CDN 节点上 ，再由 CDN 内部的同步机制将资源分散同步到每个 CDN 节点，即使 CDN 内部网络经过了优化，这个同步的过程是有延时的\nCDN 是我们系统的门面，其缓存的静态数据，如图片和视频数据的请求量很可能是接口请求数据的几倍甚至更高，一旦发生故障，对于整体系统的影响是巨大的。另外 CDN 的带宽历来是我们研发成本的大头， 尤其是目前处于小视频和直播风口上， 大量的小视频和直播研发团队都在绞尽脑汁地减少 CDN 的成本。由此看出，CDN 是我们整体系统至关重要的组成部分，而它作为一种特殊的缓存，其命中率和可用性也是我们服务端开发人员需要重点关注的指标。\n怎么迁移数据库 将数据从一个数据库拷贝到另一个数据库，可以通过 MySQL 主从同步的方式做到准实时的数据拷贝；也可以通过 mysqldump 工具将源库的数据导出，再导入到新库。这两种方式只适合单库到单库的迁移。怎么支持单库到多库多表的迁移呢？而且满足以下要求： 在线迁移，也就是迁移的时候还会有数据写入； 数据保证完整性，新库旧库数据一致； 迁移可以回滚，出现问题回滚源库；\n如果用binlog同步的方式，在同步完成以后将主库修改为新库，就不满足回滚的要求\n双写方案 新库作为源库的从库，用来同步数据，获取binlog增量日志按照分库分表的逻辑写入新库； 改造业务代码，数据写入源库的时候也写入新库，可以异步，日志记录失败，补写 校验数据，抽样检查一致性 将流量切换到新库，采用灰度发布的方式，流量慢慢增加 双写保证可以回滚，有问题就将流量切换到源库 观察几天没有问题，将数据库的双写改造为只写新库，迁移完成 好处是随时回滚，坏处是时间周期长，应用改造有成本\n级联同步方案 适合从自建机房迁移到云服务 在自建机房准备一个备库，在云上环境上准备一个新库\n将新库配置为旧库的从库，用作数据同步； 再准备一个数据库（备库）作为新库的从库，用作数据备份； 等到三个数据库写入一致后，将数据库的读流量切换到新库； 暂停应用的写入，将写流量切换到新库（要在业务低峰时操作） 回滚很简单，将读流量切换到备库，暂停应用写入，将写流量切换到备库，所有流量都到了自建机房的备库，回滚完成 应用场景：MySQL,Redis从自建机房迁移到云服务可以采用\n优势在于简单容易实施，业务没有改造成本； 缺点是切换写入的时候需要暂停写入\n迁移时如何预热缓存 缓存迁移的重点是保持缓存的热度\n使用副本组预热缓存 以memchached为例 数据写入流程是master,slave, 和所有副本组，查的时候是副本组，读不到再master和slave, 再回写副本组。 那可以在云服务上部署副本组，当足够热，也就是缓存命中率超过90%，就可以将云服务的主从都指向这个副本组，缓存迁移完成。\n足够简单，但是有问题，在于缓存穿透副本组的时候，会到自建机房的主从，跨越专线。占用专线带宽，延迟比较大，一次请求会增加几十上百毫秒的延迟，极大地影响接口响应时间。实际中很少用。\n改造副本组预热缓存 在云上部署多个副本组，自建机房接收写入请求，优先写入本地缓存节点，再异步写入云； 处理自建机房的读请求，指定一定比例的流量优先走云节点，有缓存穿透的情况，但流量可控； 当缓存命中率到90%，在云上部署应用，完全走云上的缓存节点； 这样可以控制专线的带宽和请求延迟\n","wordCount":"439","inLanguage":"en","image":"https://slowpeace2020.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-05-23T09:41:46-04:00","dateModified":"2024-05-23T09:41:46-04:00","author":[{"@type":"Person","name":"Slowpeace"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_2/"},"publisher":{"@type":"Organization","name":"slowpeace2020-blog","logo":{"@type":"ImageObject","url":"https://slowpeace2020.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://slowpeace2020.github.io/ accesskey=h title="slowpeace2020-blog (Alt + H)"><img src=https://slowpeace2020.github.io/apple-touch-icon.png alt aria-label=logo height=35>slowpeace2020-blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://slowpeace2020.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://slowpeace2020.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=https://slowpeace2020.github.io/ title=slowpeace2020><span>slowpeace2020</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://slowpeace2020.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://slowpeace2020.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">High_concurrent_distribute_system_design</h1><div class=post-description>High_concurrent_distribute_system_design introduction</div><div class=post-meta><span title='2024-05-23 09:41:46 -0400 -0400'>May 23, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;439 words&nbsp;·&nbsp;Slowpeace&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/High_concurrent_distribute_system_design_2.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#缓存定义>缓存定义</a><ul><li><a href=#静态缓存分布式缓存和热点本地缓存>静态缓存、分布式缓存和热点本地缓存</a></li></ul></li><li><a href=#缓存的缺点>缓存的缺点</a></li><li><a href=#如何选择缓存策略>如何选择缓存策略</a><ul><li><a href=#cache-aside>Cache Aside</a></li><li><a href=#readwrite-through读穿--写穿策略>Read/Write Through（读穿 / 写穿）策略</a></li><li><a href=#write-back写回策略>Write Back（写回）策略</a></li><li><a href=#总结>总结</a></li></ul></li><li><a href=#怎么保证缓存的高可用>怎么保证缓存的高可用</a><ul><li><a href=#客户端>客户端</a></li><li><a href=#中间代理层>中间代理层</a></li><li><a href=#服务端>服务端</a></li></ul></li><li><a href=#缓存穿透怎么办>缓存穿透怎么办</a><ul><li><a href=#回写空值>回写空值</a></li><li><a href=#布隆过滤器>布隆过滤器</a></li></ul></li><li><a href=#静态资源加速>静态资源加速</a><ul><li><a href=#cdn系统>CDN系统</a></li></ul></li><li><a href=#怎么迁移数据库>怎么迁移数据库</a><ul><li><a href=#双写方案>双写方案</a></li><li><a href=#级联同步方案>级联同步方案</a></li><li><a href=#迁移时如何预热缓存>迁移时如何预热缓存</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=演进篇之缓存>演进篇之缓存<a hidden class=anchor aria-hidden=true href=#演进篇之缓存>#</a></h1><h2 id=缓存定义>缓存定义<a hidden class=anchor aria-hidden=true href=#缓存定义>#</a></h2><p>凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存 。缓存作为一种常见的 空间换时间的性能优化手段。</p><p>我们熟知的 HTTP 协议也是有缓存机制的。**当我们第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个 Etag 的字段。浏览器会缓存图片信息以及这个字段的值。当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个 If-None-Match 的字段，并且把缓存的 Etag 的值写进去发给服务端。服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息。通过这种缓存协商的方式，可以减少网络传输的数据大小，从而提升页面展示的性能。</p><p>缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。 缓冲区更像「消息队列篇」中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差 。</p><h3 id=静态缓存分布式缓存和热点本地缓存>静态缓存、分布式缓存和热点本地缓存<a hidden class=anchor aria-hidden=true href=#静态缓存分布式缓存和热点本地缓存>#</a></h3><p>静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。</p><p>对于动态的请求你可以选择分布式缓存</p><p>什么时候要考虑热点本地缓存呢？</p><p>答案是当我们遇到极端的热点数据查询的时候。 热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。
我们会在代码中使用一些本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。
由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。</p><h2 id=缓存的缺点>缓存的缺点<a hidden class=anchor aria-hidden=true href=#缓存的缺点>#</a></h2><p>缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。
缓存会给整体系统带来复杂度，并且会有数据不一致的风险。
缓存通常使用内存作为存储介质，但是内存并不是无限的。
缓存会给运维也带来一定的成本。</p><p>缓存可以有多层，静态缓存处在负载均衡层，分布式缓存处在应用层和数据库层之间，本地缓存处在应用层。我们需要将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差；
缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高。</p><h2 id=如何选择缓存策略>如何选择缓存策略<a hidden class=anchor aria-hidden=true href=#如何选择缓存策略>#</a></h2><h3 id=cache-aside>Cache Aside<a hidden class=anchor aria-hidden=true href=#cache-aside>#</a></h3><p>变更数据库和变更缓存是两个独立的操作，而我们并没有对操作做任何的并发控制。那么当两个线程并发更新它们的时候，就会因为写入顺序的不同造成数据的不一致。</p><p>那我们要如何解决这个问题呢？ 其实，我们可以在更新数据时不更新缓存，而是删除缓存中的数据，在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。</p><p>Cache Aside 策略（也叫旁路缓存策略），这个策略数据 以数据库中的数据为准，缓存中的数据是按需加载的 。它可以分为读策略和写策略，</p><p>读策略的步骤是：</p><p>从缓存中读取数据；
如果缓存命中，则直接返回数据；
如果缓存不命中，则从数据库中查询数据；
查询到数据后，将数据写入到缓存中，并且返回给用户。</p><p>写策略的步骤是：</p><p>更新数据库中的记录；
删除缓存记录。</p><p>像 Cache Aside 策略这样先更新数据库，后删除缓存就没有问题了吗？
其实在理论上还是有缺陷的。假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中，造成缓存和数据库数据不一致。</p><p>不过这种问题出现的几率并不高，原因是缓存的写入通常远远快于数据库的写入 ，所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。</p><p>Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。 如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：</p><p>一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；
另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。</p><h3 id=readwrite-through读穿--写穿策略>Read/Write Through（读穿 / 写穿）策略<a hidden class=anchor aria-hidden=true href=#readwrite-through读穿--写穿策略>#</a></h3><p>这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。</p><p>Write Through 的策略是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做 Write Miss（写失效）。</p><p>我们可以选择两种 Write Miss 方式：</p><p>Write Allocate（按写分配）</p><p>做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；</p><p>No-write allocate（不按写分配）</p><p>做法是不写入缓存中，而是直接更新到数据库中</p><p>在 Write Through 策略中，我们一般选择 No-write allocate 方式，原因是无论采用哪种 Write Miss 方式，我们都需要同步将数据更新到数据库中，而 No-write allocate 方式相比 Write Allocate 还减少了一次缓存的写入，能够提升写入的性能。</p><p>Read Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。</p><p>Read Through/Write Through 策略的特点是 **由缓存节点而非用户来和数据库打交道 **，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。</p><p>我们看到 Write Through 策略中写数据库是同步的 ，这对于性能来说会有比较大的影响，因为相比于写缓存，同步写数据库的延迟就要高很多了。那么我们可否异步地更新数据库？这就是我们接下来要提到的 Write Back 策略。</p><h3 id=write-back写回策略>Write Back（写回）策略<a hidden class=anchor aria-hidden=true href=#write-back写回策略>#</a></h3><p>在写入数据时只写入缓存，并且把缓存块标记为 「脏」 的。而脏块只有被再次使用时才会将其中的数据写入到后端存储中。</p><p>在 Write Miss 的情况下，我们采用的是 Write Allocate 的方式，也就是在写入后端存储的同时要写入缓存，这样我们在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了</p><p>其实这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑。</p><p>也可以用在日志、统计等实时性不高的场景</p><h3 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h3><p>Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。</p><p>Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；</p><p>Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。</p><h2 id=怎么保证缓存的高可用>怎么保证缓存的高可用<a hidden class=anchor aria-hidden=true href=#怎么保证缓存的高可用>#</a></h2><p>分布式缓存三大类</p><h3 id=客户端>客户端<a hidden class=anchor aria-hidden=true href=#客户端>#</a></h3><p>客户端配置缓存节点
写入时将数据分散到多个节点，也就是数据分片
读则利用多组缓存做容错，提升缓存系统的可用性，</p><h4 id=怎么分片>怎么分片？<a hidden class=anchor aria-hidden=true href=#怎么分片>#</a></h4><ol><li><p>取模，实现简单，但是增减节点比较麻烦</p></li><li><p>一致性哈希，用虚拟节点解决热点数据分布不均匀的问题，可能会产生脏数据，设置过期时间
缺点是让缓存的使用变得复杂，在批量获取（MultiGET）时，单个节点的访问量并没有减少，而且节点太多会造成缓存访问的SLA(服务等级协议)得不到保证，因为它取决于最慢、最坏的节点，4-6个节点比较合适</p></li></ol><h4 id=memchached-主从机制>Memchached 主从机制<a hidden class=anchor aria-hidden=true href=#memchached-主从机制>#</a></h4><p>redis支持，但是memcached不支持，怎么在客户端实现呢？
为每一组 Master 配置一组 Slave，更新数据时主从同步更新。读取时，优先从 Slave 中读数据，如果读取不到数据就穿透到 Master 读取，并且将数据回种到 Slave 中以保持 Slave 数据的热度。
主从机制最大的优点就是当某一个 Slave 宕机时，还会有 Master 作为兜底，不会有大量请求穿透到数据库的情况发生，提升了缓存系统的高可用性。</p><h4 id=多副本>多副本<a hidden class=anchor aria-hidden=true href=#多副本>#</a></h4><p>主从模式解决绝大多数场景，极端流量场景下，一组slave不能承担所有流量，Slave的网卡带宽可能成为瓶颈，可以考虑在 Master/Slave 之前增加一层副本层
当客户端发起查询请求时，请求首先会先从多个副本组中选取一个副本组发起查询，如果查询失败，就继续查询 Master/Slave，并且将查询的结果回种到所有副本组中，避免副本组中脏数据的存在。</p><p>基于成本的考虑，每一个副本组容量比 Master 和 Slave 要小，因此它只存储了更加热的数据。</p><p>客户端方案可以解决大部分问题，但是只能在单一语言系统之间复用。中间代理层可以解决这个问题。</p><h3 id=中间代理层>中间代理层<a hidden class=anchor aria-hidden=true href=#中间代理层>#</a></h3><p>将客户端方案中的高可用逻辑封装在代理层代码里面，这样用户在使用你的代理层的时候就不需要关心缓存的高可用是如何做的，只需要依赖你的代理层就好了。
业界的中间代理层方案，比如 Facebook 的 Mcrouter，Twitter 的 Twemproxy，豌豆荚的 Codis
<img loading=lazy src=../../assets/images/middle.png alt=中间代理层></p><p>所有缓存的 读写请求 都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用的逻辑，不同的开源中间代理层方案中使用的高可用策略各有不同。比如在 Twemproxy 中，Proxy 保证在某一个 Redis 节点挂掉之后会把它从集群中移除，后续的请求将由其他节点来完成；而 Codis 的实现略复杂，它提供了一个叫 Codis Ha 的工具来实现自动从节点提主节点，在 3.2 版本之后换做了 Redis Sentinel 方式，从而实现 Redis 节点的高可用。</p><h3 id=服务端>服务端<a hidden class=anchor aria-hidden=true href=#服务端>#</a></h3><p>Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性。</p><h2 id=缓存穿透怎么办>缓存穿透怎么办<a hidden class=anchor aria-hidden=true href=#缓存穿透怎么办>#</a></h2><p>我们解决缓存穿透问题的 核心目标在于减少对于数据库的并发请求。
核心缓存的命中率要保持在 99% 以上，非核心缓存的命中率也要尽量保证在 90%，如果低于这个标准，那么可能就需要优化缓存的使用方式了。</p><h3 id=回写空值>回写空值<a hidden class=anchor aria-hidden=true href=#回写空值>#</a></h3><p>不存在的数据会反复查询数据库，或者由于bug，那就写一个空值在缓存中，设置较短的过期时间。要注意大量空值的情况，考虑缓存容量</p><h3 id=布隆过滤器>布隆过滤器<a hidden class=anchor aria-hidden=true href=#布隆过滤器>#</a></h3><p>布隆过滤器是由一个二进制数组和一个 Hash 算法组成的
针对容量大的情况，用布隆过滤器映射所有数据，提前判断是否有值，没有就直接挡住，不必再查
读写时间复杂度都是O(1)</p><p>缺点：
误判，有可能不在，但是判断存在集合中；
不支持删除元素；</p><p>解决方案：</p><ol><li>使用多个hash函数计算出多个hash值，只有都为1，才代表存在；</li><li>数组中不再只有0和1，根据出现次数计数，删除时减一；</li></ol><p>热点数据失效，导致缓存并发穿透，怎么解决？</p><ol><li>代码中启动后台线程，热点缓存失效之后将数据加载到缓存；</li><li>memcached或者redis分布式锁，只有获取到锁的请求才能查询数据库；</li></ol><h2 id=静态资源加速>静态资源加速<a hidden class=anchor aria-hidden=true href=#静态资源加速>#</a></h2><p>静态资源访问关键点：就近访问</p><p>在业务服务器上层，增加特殊的缓存，来承担静态资源访问：CDN</p><h3 id=cdn系统>CDN系统<a hidden class=anchor aria-hidden=true href=#cdn系统>#</a></h3><p>怎么把用户的请求映射到CDN节点？
怎么根据用户的地理位置信息选择近的节点？</p><p>静态资源url处理，将第三方厂商提供的 IP 隐藏起来，给到用户的最好是一个本公司域名的子域名。
通过DNS解决域名映射问题，域名解析两种方式：</p><ol><li>A记录，返回域名对应IP；</li><li>CNAME域名，返回另外一个域名；</li></ol><h4 id=域名解析步骤>域名解析步骤？<a hidden class=anchor aria-hidden=true href=#域名解析步骤>#</a></h4><p>以 <a href=https://www.baidu.com>www.baidu.com</a> 这个域名为例给你简单介绍一下域名解析的过程：</p><p>一开始，域名解析请求先会检查本机的 hosts 文件，查看是否有 <a href=https://www.baidu.com>www.baidu.com</a> 对应的 IP；</p><p>如果没有的话，就请求 Local DNS 是否有域名解析结果的缓存，如果有就返回，标识是从非权威 DNS 返回的结果；</p><p>如果没有，就开始 DNS 的迭代查询：</p><p>先请求根 DNS，根 DNS 返回顶级 DNS（.com）的地址；
再请求 .com 顶级 DNS，得到 baidu.com 的域名服务器地址；
再从 baidu.com 的域名服务器中查询到 <a href=https://www.baidu.com>www.baidu.com</a> 对应的 IP 地址，返回这个 IP 地址的同时，标记这个结果是来自于权威 DNS 的结果，同时写入 Local DNS 的解析结果缓存，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。
经过了向多个 DNS 服务器做查询之后，整个 DNS 的解析的时间有可能会到秒级别。</p><h4 id=那么我们如何来解决这个解析性能问题呢>那么我们如何来解决这个解析性能问题呢？<a hidden class=anchor aria-hidden=true href=#那么我们如何来解决这个解析性能问题呢>#</a></h4><p>在APP启动时，对要解析的域名预先解析，将解析结果缓存到本地LRU缓存，用定时器定期更新缓存</p><h4 id=global-server-load-balance全局负载均衡>Global Server Load Balance，全局负载均衡<a hidden class=anchor aria-hidden=true href=#global-server-load-balance全局负载均衡>#</a></h4><p>作用：</p><ol><li>负载均衡；</li><li>保证流量流经的服务器离流量源头近；</li></ol><p>找到离用户最近的CDN节点
是否能够从 CDN 节点上获取到资源还取决于 CDN 的同步延时。 一般，我们会通过 CDN 厂商的接口将静态的资源写入到某一个 CDN 节点上 ，再由 CDN 内部的同步机制将资源分散同步到每个 CDN 节点，即使 CDN 内部网络经过了优化，这个同步的过程是有延时的</p><p>CDN 是我们系统的门面，其缓存的静态数据，如图片和视频数据的请求量很可能是接口请求数据的几倍甚至更高，一旦发生故障，对于整体系统的影响是巨大的。另外 CDN 的带宽历来是我们研发成本的大头， 尤其是目前处于小视频和直播风口上， 大量的小视频和直播研发团队都在绞尽脑汁地减少 CDN 的成本。由此看出，CDN 是我们整体系统至关重要的组成部分，而它作为一种特殊的缓存，其命中率和可用性也是我们服务端开发人员需要重点关注的指标。</p><h2 id=怎么迁移数据库>怎么迁移数据库<a hidden class=anchor aria-hidden=true href=#怎么迁移数据库>#</a></h2><p>将数据从一个数据库拷贝到另一个数据库，可以通过 MySQL 主从同步的方式做到准实时的数据拷贝；也可以通过 mysqldump 工具将源库的数据导出，再导入到新库。这两种方式只适合单库到单库的迁移。怎么支持单库到多库多表的迁移呢？而且满足以下要求：
在线迁移，也就是迁移的时候还会有数据写入；
数据保证完整性，新库旧库数据一致；
迁移可以回滚，出现问题回滚源库；</p><p>如果用binlog同步的方式，在同步完成以后将主库修改为新库，就不满足回滚的要求</p><h3 id=双写方案>双写方案<a hidden class=anchor aria-hidden=true href=#双写方案>#</a></h3><ol><li>新库作为源库的从库，用来同步数据，获取binlog增量日志按照分库分表的逻辑写入新库；</li><li>改造业务代码，数据写入源库的时候也写入新库，可以异步，日志记录失败，补写</li><li>校验数据，抽样检查一致性</li><li>将流量切换到新库，采用灰度发布的方式，流量慢慢增加</li><li>双写保证可以回滚，有问题就将流量切换到源库</li><li>观察几天没有问题，将数据库的双写改造为只写新库，迁移完成</li></ol><p>好处是随时回滚，坏处是时间周期长，应用改造有成本</p><h3 id=级联同步方案>级联同步方案<a hidden class=anchor aria-hidden=true href=#级联同步方案>#</a></h3><p>适合从自建机房迁移到云服务
在自建机房准备一个备库，在云上环境上准备一个新库</p><ol><li>将新库配置为旧库的从库，用作数据同步；</li><li>再准备一个数据库（备库）作为新库的从库，用作数据备份；</li><li>等到三个数据库写入一致后，将数据库的读流量切换到新库；</li><li>暂停应用的写入，将写流量切换到新库（要在业务低峰时操作）</li><li>回滚很简单，将读流量切换到备库，暂停应用写入，将写流量切换到备库，所有流量都到了自建机房的备库，回滚完成</li></ol><p>应用场景：MySQL,Redis从自建机房迁移到云服务可以采用</p><p>优势在于简单容易实施，业务没有改造成本；
缺点是切换写入的时候需要暂停写入</p><h3 id=迁移时如何预热缓存>迁移时如何预热缓存<a hidden class=anchor aria-hidden=true href=#迁移时如何预热缓存>#</a></h3><p>缓存迁移的重点是保持缓存的热度</p><h4 id=使用副本组预热缓存>使用副本组预热缓存<a hidden class=anchor aria-hidden=true href=#使用副本组预热缓存>#</a></h4><p>以memchached为例
数据写入流程是master,slave, 和所有副本组，查的时候是副本组，读不到再master和slave, 再回写副本组。
那可以在云服务上部署副本组，当足够热，也就是缓存命中率超过90%，就可以将云服务的主从都指向这个副本组，缓存迁移完成。</p><p>足够简单，但是有问题，在于缓存穿透副本组的时候，会到自建机房的主从，跨越专线。占用专线带宽，延迟比较大，一次请求会增加几十上百毫秒的延迟，极大地影响接口响应时间。实际中很少用。</p><h4 id=改造副本组预热缓存>改造副本组预热缓存<a hidden class=anchor aria-hidden=true href=#改造副本组预热缓存>#</a></h4><ol><li>在云上部署多个副本组，自建机房接收写入请求，优先写入本地缓存节点，再异步写入云；</li><li>处理自建机房的读请求，指定一定比例的流量优先走云节点，有缓存穿透的情况，但流量可控；</li><li>当缓存命中率到90%，在云上部署应用，完全走云上的缓存节点；</li></ol><p>这样可以控制专线的带宽和请求延迟</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://slowpeace2020.github.io/tags/system-design/>System Design</a></li><li><a href=https://slowpeace2020.github.io/tags/distribute/>Distribute</a></li><li><a href=https://slowpeace2020.github.io/tags/concurrent/>Concurrent</a></li></ul><nav class=paginav><a class=prev href=https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_3/><span class=title>« Prev</span><br><span>High_concurrent_distribute_system_design</span>
</a><a class=next href=https://slowpeace2020.github.io/posts/high_concurrent_distribute_system_design_1/><span class=title>Next »</span><br><span>High_concurrent_distribute_system_design</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on x" href="https://x.com/intent/tweet/?text=High_concurrent_distribute_system_design&amp;url=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f&amp;hashtags=systemdesign%2cdistribute%2cconcurrent"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f&amp;title=High_concurrent_distribute_system_design&amp;summary=High_concurrent_distribute_system_design&amp;source=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f&title=High_concurrent_distribute_system_design"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on whatsapp" href="https://api.whatsapp.com/send?text=High_concurrent_distribute_system_design%20-%20https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on telegram" href="https://telegram.me/share/url?text=High_concurrent_distribute_system_design&amp;url=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share High_concurrent_distribute_system_design on ycombinator" href="https://news.ycombinator.com/submitlink?t=High_concurrent_distribute_system_design&u=https%3a%2f%2fslowpeace2020.github.io%2fposts%2fhigh_concurrent_distribute_system_design_2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://slowpeace2020.github.io/>slowpeace2020-blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>